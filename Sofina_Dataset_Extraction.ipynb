{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poenzel/sofina/blob/main/Sofina_Dataset_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction de datasets (csv) à partir de pdf\n",
        "Ce notebook emploie des méthodes de détection de tables afin d'extraire les informations. Passer par des modèles de ML entrainés est dû au grand nombre de formats différents employant des cellules mergées, ainsi que la présence de watermark dans ces pdfs qui recouvrent les tables.\n",
        "\n",
        "## Ordre des opérations :    \n",
        "### 1. Charger le(s) pdf(s)\n",
        "### 2. Transformer chaque page du(des) pdf(s) en image\n",
        "### 3. Détecter sur l'image les tables\n",
        "### 4. Identifier les cellules ainsi que leur contenu\n",
        "### 5. S'assurer que les cellules soient alignés afin d'avoir un tableau cohérent\n",
        "### 6. Merge le tout\n",
        "\n",
        "## Après l'extraction :\n",
        "Une fois les données à disposition, des étapes de cleaning supplémentaires seront encore nécessaires. Cependant, le contenu des cellules sera correct. Il faudra juste éliminer les termes parasites restants (par exemple, '.com' qui apparait à cause de la watermark) et adapter le format si nécessaire.\n",
        "\n",
        "Certains .csv ne vont contenir que du texte sur une colonne => on peut les convertir en texte à étudier si besoin. L'idée ici c'est qu'on extrait un maximum d'information.\n",
        "\n",
        "Par endroits, certaines colonnes sont \"coupées\"; cela vaudrait la peine de voir si d'autres modèles permettraient de mieux identifier les zones tabulaires, ou si on est capable de fine-tune ce modèle-ci pour nos cas.\n",
        "\n",
        "Les données ne sont pas parfaites pour l'instant, mais l'objectif c'est d'avoir un délivrable pour une \"démonstration\". On pourra polir tout le reste par la suite, quand un budget sera débloqué ou même en continuant d'avancer sur le end product, si tout va bien."
      ],
      "metadata": {
        "id": "n7AclDQUNwXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importer les packages & autres dépendances"
      ],
      "metadata": {
        "id": "WlQQdW6U1T4D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZfEBgTK5S3J"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyQjmBMn5b0Y"
      },
      "outputs": [],
      "source": [
        "!pip install pdf2image\n",
        "!apt-get install poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vl_PiN7VCcm7"
      },
      "outputs": [],
      "source": [
        "!wget https://paddleocr.bj.bcebos.com/whl/layoutparser-0.0.0-py3-none-any.whl\n",
        "!pip install -U layoutparser-0.0.0-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLlemR01CzCG"
      },
      "outputs": [],
      "source": [
        "!python3 -m pip install paddlepaddle-gpu\n",
        "!pip install \"paddleocr>=2.0.1\"\n",
        "!pip install protobuf==3.20.0\n",
        "!git clone https://github.com/PaddlePaddle/PaddleOCR.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AGoofPtI5ybe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pdf2image import convert_from_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FrZlmeWkTFge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6870c10-d46a-4cd2-8142-82cb6052b402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/paddle/base/framework.py:688: UserWarning: You are using GPU version Paddle, but your CUDA device is not set properly. CPU device will be used by default.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import layoutparser as lp\n",
        "import pandas as pd\n",
        "from paddleocr import PaddleOCR, draw_ocr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer les pdfs en série d'images\n",
        "Afin de les traiter convenablement, il faut créer un folder spécifique pour chaque pdf."
      ],
      "metadata": {
        "id": "tTaY3sHUTajl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctxPltKH57K2"
      },
      "outputs": [],
      "source": [
        "# Create the subfolders that will contain each image of each page for each pdf file\n",
        "main_path = '/content/drive/MyDrive/Sofina/Dataset1'\n",
        "\n",
        "for folder in os.listdir(main_path) :\n",
        "  # Define path for each company folder\n",
        "  folder_path = os.path.join(main_path, folder)\n",
        "\n",
        "  for file in os.listdir(folder_path) :\n",
        "    # If it's not a pdf file, skip\n",
        "    if os.path.splitext(file)[1] != '.pdf' :\n",
        "      continue\n",
        "\n",
        "    # Define path for each pdf file\n",
        "    file_path = os.path.join(folder_path, file)\n",
        "    # Get the name of the pdf file, so that we know where to store the pages\n",
        "    pdf_name = os.path.splitext(file_path)[0]\n",
        "\n",
        "    pages_folder = os.path.join(folder_path,pdf_name)\n",
        "    print('Creating folder :', pages_folder)\n",
        "    if os.path.isdir(pages_folder) :\n",
        "      print('The folder already exists.')\n",
        "    else :\n",
        "      os.mkdir(pages_folder)\n",
        "      print('New folder has been created :', pages_folder)\n",
        "\n",
        "    # Convert each page into a jpg file and store it in the newly created folder\n",
        "    images = convert_from_path(file_path)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "      page_prefix_path = os.path.join(pages_folder,'page')\n",
        "      images[i].save(page_prefix_path+str(i)+'.jpg','JPEG')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraire les données tabulaires des images"
      ],
      "metadata": {
        "id": "PsPbiWsy1dtU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "d4pUr26I6GxH"
      },
      "outputs": [],
      "source": [
        "def page_to_dataset(folder_path, page_path) :\n",
        "    # Get the path of the page\n",
        "    page = os.path.splitext(os.path.basename(page_path))[0]\n",
        "\n",
        "    # Create a specific folder to store temporary images & output datasets for that page\n",
        "    page_dataset_path = os.path.join(folder_path, page)\n",
        "    print('Creating folder :',page_dataset_path)\n",
        "    if os.path.isdir(page_dataset_path) :\n",
        "      print('The folder already exists.')\n",
        "    else :\n",
        "      os.mkdir(page_dataset_path)\n",
        "      print('New folder has been created :', page_dataset_path)\n",
        "\n",
        "    # Initiate the model for table/text detection\n",
        "    image = cv2.imread(page_path)\n",
        "    image = image[..., ::-1]\n",
        "\n",
        "    model = lp.PaddleDetectionLayoutModel(config_path= \"lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config\",\n",
        "                                        threshold = 0.5,\n",
        "                                        label_map= {0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4:\"Figure\"},\n",
        "                                        enforce_cpu = True,\n",
        "                                        enable_mkldnn= True)\n",
        "    layout = model.detect(image)\n",
        "\n",
        "    # Initiate the Optical Character Recognition tool\n",
        "    ocr = PaddleOCR(lang='en', use_gpu = False)\n",
        "\n",
        "    box_nb = 0\n",
        "    #Let's iterate through each detected zones and compute the resulting dataset (even if it's text)\n",
        "    for layout_block in layout :\n",
        "        # Note : this condition should actually skip each block except Tables, but due to special formats (and a gigantic\n",
        "        # watermark that covers everything)\n",
        "        # if layout_block.type  == 'Title' :\n",
        "        #     box_nb += 1\n",
        "        #     continue\n",
        "\n",
        "        # Get the coordinates of the frame of the detected text entity\n",
        "        x_1 = int(layout_block.block.x_1)\n",
        "        y_1 = int(layout_block.block.y_1)\n",
        "        x_2 = int(layout_block.block.x_2)\n",
        "        y_2 = int(layout_block.block.y_2)\n",
        "\n",
        "        # Define a temporary image on which identifying boxes around values\n",
        "        temp_img = page +'_temp1_'+str(box_nb) + '.jpg'\n",
        "        temp_img_path = os.path.join(page_dataset_path,temp_img)\n",
        "        im2 = cv2.imread(page_path)\n",
        "        cv2.imwrite(temp_img_path, im2[y_1:y_2,x_1:x_2])\n",
        "\n",
        "\n",
        "        image_cv = cv2.imread(temp_img_path)\n",
        "        image_height = image_cv.shape[0]\n",
        "        image_width = image_cv.shape[1]\n",
        "\n",
        "        # # Initiate the Optical Character Recognition tool\n",
        "        # ocr = PaddleOCR(lang='en', use_gpu = False)\n",
        "        output = ocr.ocr(temp_img_path)\n",
        "\n",
        "        if output[0] is None :\n",
        "          continue\n",
        "\n",
        "        boxes = [line[0] for line in output[0]]\n",
        "        texts = [line[1][0] for line in output[0]]\n",
        "        probabilities = [line[1][1] for line in output[0]]\n",
        "\n",
        "        # Define another temporary image to get & check if values & cells are correctly identified\n",
        "        temp_img_2 = page + '_temp2_' + str(box_nb) + '.jpg'\n",
        "        temp_img_2_path = os.path.join(page_dataset_path,temp_img_2)\n",
        "        image_boxes = image_cv.copy()\n",
        "        for box,text in zip(boxes,texts):\n",
        "            cv2.rectangle(image_boxes, (int(box[0][0]),int(box[0][1])), (int(box[2][0]),int(box[2][1])),(0,0,255),1)\n",
        "            cv2.putText(image_boxes, text,(int(box[0][0]),int(box[0][1])),cv2.FONT_HERSHEY_SIMPLEX,1,(222,0,0),1)\n",
        "            cv2.imwrite(temp_img_2_path, image_boxes)\n",
        "\n",
        "        # Let's rebuild the interpreted dataset from what has been detected\n",
        "        im = image_cv.copy()\n",
        "        horiz_boxes = []\n",
        "        vert_boxes = []\n",
        "\n",
        "        for box in boxes:\n",
        "          x_h, x_v = 0,int(box[0][0])\n",
        "          y_h, y_v = int(box[0][1]),0\n",
        "\n",
        "          # Difference between the min & max x-coordinate of the box\n",
        "          width_h,width_v = image_width, int(box[2][0]-box[0][0])\n",
        "          # Same on the y axis\n",
        "          height_h,height_v = int(box[2][1]-box[0][1]),image_height\n",
        "\n",
        "          horiz_boxes.append([x_h,y_h,x_h+width_h,y_h+height_h])\n",
        "          vert_boxes.append([x_v,y_v,x_v+width_v,y_v+height_v])\n",
        "\n",
        "          cv2.rectangle(im,(x_h,y_h), (x_h+width_h,y_h+height_h),(0,0,255),1)\n",
        "          cv2.rectangle(im,(x_v,y_v), (x_v+width_v,y_v+height_v),(0,255,0),1)\n",
        "\n",
        "        temp_img_3 = page + '_temp3_' + str(box_nb) + '.jpg'\n",
        "        temp_img_3_path = os.path.join(page_dataset_path,temp_img_3)\n",
        "        cv2.imwrite(temp_img_3_path,im)\n",
        "\n",
        "        # Keep only the boxes with the best scores (the least IOU)\n",
        "        # We can play with the iou_threshold to get + or - boxes\n",
        "        horiz_out = tf.image.non_max_suppression(\n",
        "            horiz_boxes,\n",
        "            probabilities,\n",
        "            max_output_size = 500,\n",
        "            iou_threshold=0.1,\n",
        "            score_threshold=float('-inf'),\n",
        "            name=None\n",
        "        )\n",
        "\n",
        "\n",
        "        temp_img_4 = page+ '_finalBox_' + str(box_nb) + '.jpg'\n",
        "        temp_img_4_path = os.path.join(page_dataset_path, temp_img_4)\n",
        "\n",
        "        horiz_lines = np.sort(np.array(horiz_out))\n",
        "        im_nms = image_cv.copy()\n",
        "        for val in horiz_lines:\n",
        "            cv2.rectangle(im_nms, (int(horiz_boxes[val][0]),int(horiz_boxes[val][1])), (int(horiz_boxes[val][2]),int(horiz_boxes[val][3])),(0,0,255),1)\n",
        "        cv2.imwrite(temp_img_4_path,im_nms)\n",
        "\n",
        "        # Keep only the boxes with the best scores again (vertical boxes in this case)\n",
        "        # Again, we can play with the iou_threshold if needed\n",
        "        vert_out = tf.image.non_max_suppression(\n",
        "            vert_boxes,\n",
        "            probabilities,\n",
        "            max_output_size = 100, # we could get the maximum table size manually\n",
        "            iou_threshold=0.1,\n",
        "            score_threshold=float('-inf'),\n",
        "            name=None\n",
        "        )\n",
        "        vert_lines = np.sort(np.array(vert_out))\n",
        "\n",
        "        for val in vert_lines:\n",
        "            cv2.rectangle(im_nms, (int(vert_boxes[val][0]),int(vert_boxes[val][1])), (int(vert_boxes[val][2]),int(vert_boxes[val][3])),(255,0,0),1)\n",
        "\n",
        "        cv2.imwrite(temp_img_4_path,im_nms)\n",
        "\n",
        "        # Transform the resulting image into a table\n",
        "        out_array = [[\"\" for i in range(len(vert_lines))] for j in range(len(horiz_lines))]\n",
        "        unordered_boxes = []\n",
        "\n",
        "        for i in vert_lines:\n",
        "            unordered_boxes.append(vert_boxes[i][0])\n",
        "        ordered_boxes = np.argsort(unordered_boxes)\n",
        "\n",
        "        def intersection(box_1, box_2):\n",
        "            return [box_2[0], box_1[1],box_2[2], box_1[3]]\n",
        "\n",
        "        def iou(box_1, box_2):\n",
        "\n",
        "            x_1 = max(box_1[0], box_2[0])\n",
        "            y_1 = max(box_1[1], box_2[1])\n",
        "            x_2 = min(box_1[2], box_2[2])\n",
        "            y_2 = min(box_1[3], box_2[3])\n",
        "\n",
        "            inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
        "            if inter == 0:\n",
        "                return 0\n",
        "\n",
        "            box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
        "            box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
        "\n",
        "            return inter / float(box_1_area + box_2_area - inter)\n",
        "\n",
        "        for i in range(len(horiz_lines)):\n",
        "            for j in range(len(vert_lines)):\n",
        "                resultant = intersection(horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]] )\n",
        "\n",
        "                for b in range(len(boxes)):\n",
        "                    the_box = [boxes[b][0][0],boxes[b][0][1],boxes[b][2][0],boxes[b][2][1]]\n",
        "                    if(iou(resultant,the_box)>0.1):\n",
        "                        out_array[i][j] = texts[b]\n",
        "\n",
        "        out_array=np.array(out_array)\n",
        "\n",
        "        output_dataset = page + '_dataset_' + str(box_nb) + '.csv'\n",
        "        output_dataset_path = os.path.join(page_dataset_path, output_dataset)\n",
        "        pd.DataFrame(out_array).to_csv(output_dataset_path)\n",
        "\n",
        "        box_nb +=1\n",
        "\n",
        "    for filename in os.listdir(page_dataset_path) :\n",
        "      if os.path.splitext(filename)[1] != '.jpg' or 'finalBox' in filename :\n",
        "        continue\n",
        "      else :\n",
        "        os.remove(os.path.join(page_dataset_path,filename))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Too much RAM required ###\n",
        "\n",
        "# from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# # Iterate over each company folder\n",
        "# for folder in os.listdir(main_path):\n",
        "#     folder_path = os.path.join(main_path, folder)\n",
        "\n",
        "#     # Access each subfolder within the company folder\n",
        "#     for subfolder in os.listdir(folder_path):\n",
        "#         subfolder_path = os.path.join(folder_path, subfolder)\n",
        "\n",
        "#         # Check if the subfolder is a directory\n",
        "#         if os.path.isdir(subfolder_path):\n",
        "#             # Use a ThreadPoolExecutor to parallelize image processing\n",
        "#             with ThreadPoolExecutor() as executor:\n",
        "#                 # Iterate over each image in the subfolder\n",
        "#                 for page_img in os.listdir(subfolder_path):\n",
        "#                   if os.path.splitext(page_img)[1] != '.jpg':\n",
        "#                     continue\n",
        "#                   # Submit the image processing task to the executor\n",
        "#                   page_path = os.path.join(subfolder_path, page_img)\n",
        "#                   executor.submit(page_to_dataset, subfolder_path, page_path)\n"
      ],
      "metadata": {
        "id": "ip_iR36i58XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdfD0vNySUIt"
      },
      "outputs": [],
      "source": [
        "### THIS TAKES A LONG TIME if run on all folders (3-4h) --> Better run a folder at a time. ###\n",
        "chosen_folder = ['THOMA BRAVO']\n",
        "\n",
        "for folder in os.listdir(main_path) : # change \"in os.listdir(main_path)\" to \"in chosen_folder\" to execute on a single company\n",
        "  folder_path = os.path.join(main_path, folder)\n",
        "  # Access to each company folder\n",
        "  for subfolder in os.listdir(folder_path) :\n",
        "    subfolder_path = os.path.join(folder_path, subfolder)\n",
        "    # If we access a folder we created before\n",
        "    if os.path.isdir(subfolder_path) :\n",
        "      # Access to each image and run the function defined above for each image\n",
        "      for page_img in os.listdir(subfolder_path) :\n",
        "        if os.path.splitext(page_img)[1] != '.jpg' :\n",
        "          continue\n",
        "        page_path = os.path.join(subfolder_path,page_img)\n",
        "        page_to_dataset(subfolder_path, page_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6gqriP7lFNO"
      },
      "source": [
        "## En dessous :\n",
        "Tentatives d'exploiter les coordonnées obtenues. Un des problèmes vient de la watermark..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9Qnz6i2WDz7",
        "outputId": "5e32eb1a-3df8-4a53-bbe8-7c7ca3227fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tabula-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sdx843IjLIV",
        "outputId": "f173e649-c4ff-4375-c7e7-8e16b7547990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting img2table\n",
            "  Downloading img2table-1.2.8-py3-none-any.whl (91 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.4/91.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: polars[pandas]>=0.19.14 in /usr/local/lib/python3.10/dist-packages (from img2table) (0.20.2)\n",
            "Requirement already satisfied: pyarrow>=7 in /usr/local/lib/python3.10/dist-packages (from img2table) (10.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from img2table) (1.23.5)\n",
            "Requirement already satisfied: pymupdf>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from img2table) (1.20.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from img2table) (4.6.0.66)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from img2table) (0.58.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from img2table) (4.11.2)\n",
            "Collecting xlsxwriter>=3.0.6 (from img2table)\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from polars[pandas]>=0.19.14->img2table) (1.5.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->img2table) (2.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->img2table) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->polars[pandas]>=0.19.14->img2table) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->polars[pandas]>=0.19.14->img2table) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->polars[pandas]>=0.19.14->img2table) (1.16.0)\n",
            "Installing collected packages: xlsxwriter, img2table\n",
            "Successfully installed img2table-1.2.8 xlsxwriter-3.1.9\n"
          ]
        }
      ],
      "source": [
        "!pip install img2table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZORoNq0YFTV"
      },
      "outputs": [],
      "source": [
        "# import tabula\n",
        "from img2table.document import Image\n",
        "\n",
        "path = '/content/drive/MyDrive/Sofina/Dataset1/ANDREESSEN & HOROWITZ/pages/ext_im.jpg'\n",
        "\n",
        "img = Image(src=path)\n",
        "\n",
        "# Table identification\n",
        "img_tables = img.extract_tables()\n",
        "\n",
        "# Result of table identification\n",
        "img_tables\n",
        "# custom_area = (208.52716064453125-104, 284.2144775390625-142, 1995.473876953125+104, 1469.7366943359375+142)\n",
        "\n",
        "#TODO : Split la merged cell pcq même avec une custom area ça passe pas\n",
        "\n",
        "# dfs = tabula.read_pdf(path, stream = True,\n",
        "#                       # area= custom_area,\n",
        "#                       pages= '6')\n",
        "\n",
        "# dfs[0].head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRDPCZVq9CoN"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "h6gqriP7lFNO"
      ],
      "authorship_tag": "ABX9TyP9u0BhYZ3RTFsTmStnYARg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}